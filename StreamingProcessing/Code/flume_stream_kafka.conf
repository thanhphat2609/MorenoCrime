# example.conf: A single-node Flume configuration

# Name the components on this agent
a1_to_kafka.sources = r1
a1_to_kafka.sinks = k1
a1_to_kafka.channels = c1

# Describe/configure the source
a1_to_kafka.sources.r1.type = org.apache.flume.source.kafka.KafkaSource
a1_to_kafka.sources.r1.channels = c1
a1_to_kafka.sources.r1.interceptors = timestampInterceptor
a1_to_kafka.sources.r1.interceptors.timestampInterceptor.type = timestamp
a1_to_kafka.sources.r1.kafka.bootstrap.servers = 127.0.0.1:9092
a1_to_kafka.sources.r1.kafka.topics = streamTopic
a1_to_kafka.sources.r1.kafka.consumer.group.id = flume
a1_to_kafka.sources.r1.kafka.consumer.auto.offset.reset = earliest

# Describe the sink
a1_to_kafka.sinks.k1.type = hdfs
a1_to_kafka.sinks.k1.hdfs.path = /user/thanhphat/datalake/stream_moreno/%d-%m-%y/%H-%M-%S
a1_to_kafka.sinks.k1.hdfs.filePrefix = events-
a1_to_kafka.sinks.k1.hdfs.round = true
a1_to_kafka.sinks.k1.hdfs.roundValue = 10
a1_to_kafka.sinks.k1.hdfs.roundUnit = second

# Use a channel which buffers events in memory
a1_to_kafka.channels.c1.type = memory
a1_to_kafka.channels.c1.capacity = 1000
a1_to_kafka.channels.c1.transactionCapacity = 1000

# Bind the source and sink to the channel
a1_to_kafka.sources.r1.channels = c1
a1_to_kafka.sinks.k1.channel = c1

